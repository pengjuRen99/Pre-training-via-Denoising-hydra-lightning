[[36m2025-09-25 17:08:10,359[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-09-25 17:08:10,363[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.datamodule.DataModule                                
â”‚       data_dir: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-trai
â”‚       dataset_name: QM9SP                                                     
â”‚       batch_size: 128                                                         
â”‚       inference_batch_size: 128                                               
â”‚       splits: null                                                            
â”‚       train_val_test_split:                                                   
â”‚       - 110000                                                                
â”‚       - 10000                                                                 
â”‚       - null                                                                  
â”‚       num_workers: 10                                                         
â”‚       pin_memory: true                                                        
â”‚       data_arg: homo                                                          
â”‚       coord_files: null                                                       
â”‚       embed_files: null                                                       
â”‚       energy_files: null                                                      
â”‚       force_files: null                                                       
â”‚       energy_weight: 0.0                                                      
â”‚       force_weight: 0.0                                                       
â”‚       position_noise_scale: 0.04                                              
â”‚       denoising_weight: 1.0                                                   
â”‚       denoising_only: true                                                    
â”‚       standardize: false                                                      
â”‚       prior_model: null                                                       
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.module.LNNP                                        
â”‚       extras:                                                                 
â”‚         lr_warmup_steps: 10000                                                
â”‚         ema_alpha_y: 1.0                                                      
â”‚         ema_aplha_dy: 1.0                                                     
â”‚         energy_weight: 0.0                                                    
â”‚         force_weight: 0.0                                                     
â”‚         denoising_weight: 1.0                                                 
â”‚         contrastive_weight: 1.0                                               
â”‚         reconstruct_weight: 1.0                                               
â”‚       optimizer:                                                              
â”‚         _target_: torch.optim.AdamW                                           
â”‚         _partial_: true                                                       
â”‚         lr: 0.0004                                                            
â”‚         weight_decay: 0.0                                                     
â”‚       scheduler:                                                              
â”‚         _target_: torch.optim.lr_scheduler.CosineAnnealingLR                  
â”‚         _partial_: true                                                       
â”‚         T_max: 400000                                                         
â”‚       net:                                                                    
â”‚         model: equivariant-transformer                                        
â”‚         embedding_dimension: 256                                              
â”‚         num_layers: 8                                                         
â”‚         num_rbf: 64                                                           
â”‚         activation: silu                                                      
â”‚         rbf_type: expnorm                                                     
â”‚         trainable_rbf: false                                                  
â”‚         neighbor_embedding: true                                              
â”‚         aggr: add                                                             
â”‚         distance_influence: both                                              
â”‚         attn_activation: silu                                                 
â”‚         num_heads: 8                                                          
â”‚         layernorm_on_vec: whitened                                            
â”‚         derivative: false                                                     
â”‚         cutoff_lower: 0.0                                                     
â”‚         cutoff_upper: 5.0                                                     
â”‚         atom_filter: -1                                                       
â”‚         max_z: 100                                                            
â”‚         max_num_neighbors: 32                                                 
â”‚         reduce_op: add                                                        
â”‚         position_noise_scale: 0.04                                            
â”‚         load_model: null                                                      
â”‚         pretrained_model: logs/train/runs/2025-09-24_22-03-23/checkpoints/step
â”‚         prior_model: null                                                     
â”‚         output_model: Scalar                                                  
â”‚         output_model_noise: VectorOutput                                      
â”‚         reduce_lr_when_bad: false                                             
â”‚         use_dataset_md17: false                                               
â”‚         lr_factor: 0.8                                                        
â”‚         lr_patience: 15                                                       
â”‚         uv_model: SpecFormer                                                  
â”‚         input_data_norm_type: log10                                           
â”‚         output_model_spec: null                                               
â”‚         output_model_mol: null                                                
â”‚         patch_len:                                                            
â”‚         - 20                                                                  
â”‚         - 50                                                                  
â”‚         - 50                                                                  
â”‚         stride:                                                               
â”‚         - 10                                                                  
â”‚         - 25                                                                  
â”‚         - 25                                                                  
â”‚         mask_ratios:                                                          
â”‚         - 0.1                                                                 
â”‚         - 0.1                                                                 
â”‚         - 0.1                                                                 
â”‚       compile: false                                                          
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                       
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
â”‚         dirpath: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-tra
â”‚         filename: step={step}-epoch={epoch}-val_loss={val_loss:.4f}-test_loss=
â”‚         monitor: val_loss                                                     
â”‚         verbose: false                                                        
â”‚         save_last: true                                                       
â”‚         save_top_k: 10                                                        
â”‚         mode: min                                                             
â”‚         auto_insert_metric_name: false                                        
â”‚         save_weights_only: false                                              
â”‚         every_n_train_steps: null                                             
â”‚         train_time_interval: null                                             
â”‚         every_n_epochs: 1                                                     
â”‚         save_on_train_epoch_end: null                                         
â”‚       early_stopping:                                                         
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                   
â”‚         monitor: val_loss                                                     
â”‚         min_delta: 0.0                                                        
â”‚         patience: 150                                                         
â”‚         verbose: false                                                        
â”‚         mode: min                                                             
â”‚         strict: true                                                          
â”‚         check_finite: true                                                    
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       rich_progress_bar:                                                      
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                 
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ csv:                                                                    
â”‚         _target_: lightning.pytorch.loggers.csv_logs.CSVLogger                
â”‚         save_dir: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-tr
â”‚         name: QM9SP-PT                                                        
â”‚         prefix: ''                                                            
â”‚       tensorboard:                                                            
â”‚         _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger     
â”‚         save_dir: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-tr
â”‚         name: QM9SP-PT                                                        
â”‚         log_graph: false                                                      
â”‚         default_hp_metric: true                                               
â”‚         prefix: ''                                                            
â”‚       wandb:                                                                  
â”‚         _target_: lightning.pytorch.loggers.wandb.WandbLogger                 
â”‚         save_dir: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-tr
â”‚         offline: false                                                        
â”‚         id: null                                                              
â”‚         anonymous: null                                                       
â”‚         project: QM9SP-PT                                                     
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         group: ''                                                             
â”‚         tags: []                                                              
â”‚         job_type: ''                                                          
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/
â”‚       min_epochs: 1                                                           
â”‚       max_epochs: 3000                                                        
â”‚       max_steps: 400000                                                       
â”‚       accelerator: gpu                                                        
â”‚       devices: 1                                                              
â”‚       precision: 32                                                           
â”‚       check_val_every_n_epoch: 1                                              
â”‚       deterministic: false                                                    
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-trai
â”‚       data_dir: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-trai
â”‚       log_dir: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-train
â”‚       output_dir: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-tr
â”‚       work_dir: /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-trai
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train                                                                   
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['QM9SP-PT']                                                            
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ test
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ None                                                                    
â””â”€â”€ seed
    â””â”€â”€ 1                                                                       
Seed set to 1
[[36m2025-09-25 17:08:10,407[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.datamodule.DataModule>[0m
train 110000, val 10000, test 8140
[[36m2025-09-25 17:08:13,271[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.module.LNNP>[0m
[[36m2025-09-25 17:08:13,624[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-09-25 17:08:13,624[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-09-25 17:08:13,627[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-09-25 17:08:13,627[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-09-25 17:08:13,628[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-09-25 17:08:13,628[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-09-25 17:08:13,628[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.csv_logs.CSVLogger>[0m
[[36m2025-09-25 17:08:13,629[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-09-25 17:08:13,631[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>[0m
[[36m2025-09-25 17:08:13,633[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-09-25 17:08:13,671[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.[0m
[[36m2025-09-25 17:08:13,676[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - GPU available: True (cuda), used: True[0m
[[36m2025-09-25 17:08:13,676[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - TPU available: False, using: 0 TPU cores[0m
[[36m2025-09-25 17:08:13,676[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - HPU available: False, using: 0 HPUs[0m
[[36m2025-09-25 17:08:13,676[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
/home/RenPengju/.local/share/mamba/envs/AllAtomDiff/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
wandb: Currently logged in as: pengjuren99 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: creating run
wandb: Tracking run with wandb version 0.21.2
wandb: Run data is saved locally in /home/RenPengju/code/MultiModal_Spectra/Pretrain_task/Pre-training-via-Denoising-hydra-lightning/logs/train/runs/2025-09-25_17-08-10/wandb/run-20250925_170815-ua5jfan1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-plasma-1
wandb: â­ï¸ View project at https://wandb.ai/pengjuren99/QM9SP-PT
wandb: ğŸš€ View run at https://wandb.ai/pengjuren99/QM9SP-PT/runs/ua5jfan1
[[36m2025-09-25 17:08:17,871[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
[[36m2025-09-25 17:08:17,876[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - You are using a CUDA device ('NVIDIA GeForce RTX 5090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
train 110000, val 10000, test 8140
â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”³â”³â”“
â”ƒâ”ƒ Name                                                                     â”ƒâ”ƒâ”ƒâ”ƒ
â”¡â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â•‡â•‡â”©
â”‚â”‚ model                                                                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model                                               â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.embedding                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.distance                                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.distance_expansion                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.distance_expansion.cutoff_fn                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.neighbor_embedding                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.neighbor_embedding.aggr_module                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.neighbor_embedding.embedding                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.neighbor_embedding.distance_proj              â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.neighbor_embedding.combine                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.neighbor_embedding.cutoff                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers                              â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.aggr_module                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.layernorm                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.act                        â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.attn_activation            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.cutoff                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.q_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.k_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.v_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.o_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.vec_proj                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.dk_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.0.dv_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.aggr_module                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.layernorm                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.act                        â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.attn_activation            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.cutoff                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.q_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.k_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.v_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.o_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.vec_proj                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.dk_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.1.dv_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.aggr_module                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.layernorm                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.act                        â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.attn_activation            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.cutoff                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.q_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.k_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.v_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.o_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.vec_proj                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.dk_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.2.dv_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.aggr_module                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.layernorm                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.act                        â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.attn_activation            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.cutoff                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.q_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.k_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.v_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.o_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.vec_proj                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.dk_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.3.dv_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.aggr_module                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.layernorm                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.act                        â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.attn_activation            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.cutoff                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.q_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.k_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.v_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.o_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.vec_proj                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.dk_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.4.dv_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.aggr_module                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.layernorm                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.act                        â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.attn_activation            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.cutoff                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.q_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.k_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.v_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.o_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.vec_proj                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.dk_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.5.dv_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.aggr_module                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.layernorm                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.act                        â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.attn_activation            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.cutoff                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.q_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.k_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.v_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.o_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.vec_proj                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.dk_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.6.dv_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.aggr_module                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.layernorm                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.act                        â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.attn_activation            â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.cutoff                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.q_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.k_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.v_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.o_proj                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.vec_proj                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.dk_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.attention_layers.7.dv_proj                    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.x_norms                                       â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.x_norms.0                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.x_norms.1                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.x_norms.2                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.x_norms.3                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.x_norms.4                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.x_norms.5                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.x_norms.6                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.x_norms.7                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.vec_norms                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.vec_norms.0                                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.vec_norms.1                                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.vec_norms.2                                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.vec_norms.3                                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.vec_norms.4                                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.vec_norms.5                                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.vec_norms.6                                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.vec_norms.7                                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.out_norm                                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_model.out_norm_vec                                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model                                                       â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network                                        â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.0                                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.0.vec1_proj                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.0.vec2_proj                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.0.update_net                           â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.0.update_net.0                         â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.0.update_net.1                         â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.0.update_net.2                         â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.0.act                                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.1                                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.1.vec1_proj                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.1.vec2_proj                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.1.update_net                           â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.1.update_net.0                         â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.1.update_net.1                         â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model.output_network.1.update_net.2                         â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model                                          â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone                                 â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.W_P                             â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.W_P.0                           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.W_P.1                           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.W_P.2                           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.dropout                         â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder                         â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.self_attn      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.self_attn.W_Q  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.self_attn.W_K  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.self_attn.W_V  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.self_attn.sdpâ€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.self_attn.sdpâ€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.self_attn.to_â€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.self_attn.to_â€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.self_attn.to_â€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.dropout_attn   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.norm_attn      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.norm_attn.0    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.norm_attn.1    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.norm_attn.2    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.ff             â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.ff.0           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.ff.1           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.ff.2           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.ff.3           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.dropout_ffn    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.norm_ffn       â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.norm_ffn.0     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.norm_ffn.1     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.0.norm_ffn.2     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.self_attn      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.self_attn.W_Q  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.self_attn.W_K  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.self_attn.W_V  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.self_attn.sdpâ€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.self_attn.sdpâ€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.self_attn.to_â€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.self_attn.to_â€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.self_attn.to_â€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.dropout_attn   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.norm_attn      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.norm_attn.0    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.norm_attn.1    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.norm_attn.2    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.ff             â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.ff.0           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.ff.1           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.ff.2           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.ff.3           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.dropout_ffn    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.norm_ffn       â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.norm_ffn.0     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.norm_ffn.1     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.1.norm_ffn.2     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2                â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.self_attn      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.self_attn.W_Q  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.self_attn.W_K  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.self_attn.W_V  â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.self_attn.sdpâ€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.self_attn.sdpâ€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.self_attn.to_â€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.self_attn.to_â€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.self_attn.to_â€¦ â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.dropout_attn   â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.norm_attn      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.norm_attn.0    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.norm_attn.1    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.norm_attn.2    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.ff             â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.ff.0           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.ff.1           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.ff.2           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.ff.3           â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.dropout_ffn    â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.norm_ffn       â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.norm_ffn.0     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.norm_ffn.1     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.backbone.encoder.layers.2.norm_ffn.2     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.head                                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.head.flatten                             â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.head.linear                              â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.head.dropout                             â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.reconstruct_heads                        â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.reconstruct_heads.0                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.reconstruct_heads.1                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.reconstruct_heads.2                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.representation_spec_model.out_norm                                 â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise                                                 â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network                                  â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.0                                â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.0.vec1_proj                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.0.vec2_proj                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.0.update_net                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.0.update_net.0                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.0.update_net.1                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.0.update_net.2                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.0.act                            â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.1                                â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.1.vec1_proj                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.1.vec2_proj                      â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.1.update_net                     â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.1.update_net.0                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.1.update_net.1                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.output_model_noise.output_network.1.update_net.2                   â”‚â”‚â”‚â”‚
â”‚â”‚ model.pos_normalizer                                                     â”‚â”‚â”‚â”‚
â””â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”´â”´â”˜
Trainable params: 19.1 M                                                        
Non-trainable params: 3                                                         
Total params: 19.1 M                                                            
Total estimated model params size (MB): 76                                      
Modules in train mode: 265                                                      
Modules in eval mode: 0                                                         
[[36m2025-09-26 10:38:20,311[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-09-26 10:38:20,319[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.datamodule.DataModule                                
â”‚       data_dir: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectroscop
â”‚       dataset_name: PCQM4MV2                                                  
â”‚       batch_size: 70                                                          
â”‚       inference_batch_size: 70                                                
â”‚       splits: null                                                            
â”‚       train_val_test_split:                                                   
â”‚       - null                                                                  
â”‚       - 100                                                                   
â”‚       - 100                                                                   
â”‚       num_workers: 20                                                         
â”‚       pin_memory: true                                                        
â”‚       data_arg: null                                                          
â”‚       coord_files: null                                                       
â”‚       embed_files: null                                                       
â”‚       energy_files: null                                                      
â”‚       force_files: null                                                       
â”‚       energy_weight: 0.0                                                      
â”‚       force_weight: 1.0                                                       
â”‚       position_noise_scale: 0.04                                              
â”‚       denoising_weight: 1.0                                                   
â”‚       denoising_only: true                                                    
â”‚       standardize: false                                                      
â”‚       prior_model: null                                                       
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.module.LNNP                                        
â”‚       extras:                                                                 
â”‚         lr_warmup_steps: 10000                                                
â”‚         ema_alpha_y: 1.0                                                      
â”‚         ema_aplha_dy: 1.0                                                     
â”‚         energy_weight: 0.0                                                    
â”‚         force_weight: 1.0                                                     
â”‚         denoising_weight: 1.0                                                 
â”‚         contrastive_weight: 0.0                                               
â”‚         reconstruct_weight: 0.0                                               
â”‚       optimizer:                                                              
â”‚         _target_: torch.optim.AdamW                                           
â”‚         _partial_: true                                                       
â”‚         lr: 0.0004                                                            
â”‚         weight_decay: 0.0                                                     
â”‚       scheduler:                                                              
â”‚         _target_: torch.optim.lr_scheduler.CosineAnnealingLR                  
â”‚         _partial_: true                                                       
â”‚         T_max: 400000                                                         
â”‚       net:                                                                    
â”‚         model: equivariant-transformer                                        
â”‚         embedding_dimension: 128                                              
â”‚         num_layers: 6                                                         
â”‚         num_rbf: 32                                                           
â”‚         activation: silu                                                      
â”‚         rbf_type: expnorm                                                     
â”‚         trainable_rbf: false                                                  
â”‚         neighbor_embedding: true                                              
â”‚         aggr: add                                                             
â”‚         distance_influence: both                                              
â”‚         attn_activation: silu                                                 
â”‚         num_heads: 8                                                          
â”‚         layernorm_on_vec: whitened                                            
â”‚         derivative: false                                                     
â”‚         cutoff_lower: 0.0                                                     
â”‚         cutoff_upper: 5.0                                                     
â”‚         atom_filter: -1                                                       
â”‚         max_z: 100                                                            
â”‚         max_num_neighbors: 32                                                 
â”‚         reduce_op: add                                                        
â”‚         position_noise_scale: 0.04                                            
â”‚         load_model: null                                                      
â”‚         pretrained_model: null                                                
â”‚         prior_model: null                                                     
â”‚         output_model: Scalar                                                  
â”‚         output_model_noise: VectorOutput                                      
â”‚         reduce_lr_when_bad: false                                             
â”‚         lr_factor: 0.8                                                        
â”‚         lr_patience: 15                                                       
â”‚         use_dataset_md17: true                                                
â”‚         uv_model: null                                                        
â”‚         input_data_norm_type: minmax                                          
â”‚         output_model_spec: null                                               
â”‚         output_model_mol: null                                                
â”‚         patch_len:                                                            
â”‚         - 20                                                                  
â”‚         - 50                                                                  
â”‚         - 50                                                                  
â”‚         stride:                                                               
â”‚         - 10                                                                  
â”‚         - 25                                                                  
â”‚         - 25                                                                  
â”‚         reconstruct_weight: 0.0                                               
â”‚         mask_ratios:                                                          
â”‚         - 0.1                                                                 
â”‚         - 0.1                                                                 
â”‚         - 0.1                                                                 
â”‚       compile: false                                                          
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                       
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
â”‚         dirpath: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectrosco
â”‚         filename: step={step}-epoch={epoch}-val_loss={val_loss:.4f}-test_loss=
â”‚         monitor: val_loss                                                     
â”‚         verbose: false                                                        
â”‚         save_last: true                                                       
â”‚         save_top_k: 10                                                        
â”‚         mode: min                                                             
â”‚         auto_insert_metric_name: false                                        
â”‚         save_weights_only: false                                              
â”‚         every_n_train_steps: null                                             
â”‚         train_time_interval: null                                             
â”‚         every_n_epochs: 1                                                     
â”‚         save_on_train_epoch_end: null                                         
â”‚       early_stopping:                                                         
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                   
â”‚         monitor: val_loss                                                     
â”‚         min_delta: 0.0                                                        
â”‚         patience: 150                                                         
â”‚         verbose: false                                                        
â”‚         mode: min                                                             
â”‚         strict: true                                                          
â”‚         check_finite: true                                                    
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       rich_progress_bar:                                                      
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                 
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ csv:                                                                    
â”‚         _target_: lightning.pytorch.loggers.csv_logs.CSVLogger                
â”‚         save_dir: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectrosc
â”‚         name: MD17-pcqm4mv2-PT                                                
â”‚         prefix: ''                                                            
â”‚       tensorboard:                                                            
â”‚         _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger     
â”‚         save_dir: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectrosc
â”‚         name: MD17-pcqm4mv2-PT                                                
â”‚         log_graph: false                                                      
â”‚         default_hp_metric: true                                               
â”‚         prefix: ''                                                            
â”‚       wandb:                                                                  
â”‚         _target_: lightning.pytorch.loggers.wandb.WandbLogger                 
â”‚         save_dir: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectrosc
â”‚         offline: false                                                        
â”‚         id: null                                                              
â”‚         anonymous: null                                                       
â”‚         project: MD17-pcqm4mv2-PT                                             
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         group: ''                                                             
â”‚         tags: []                                                              
â”‚         job_type: ''                                                          
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spe
â”‚       min_epochs: 1                                                           
â”‚       max_epochs: 30                                                          
â”‚       max_steps: 400000                                                       
â”‚       accelerator: gpu                                                        
â”‚       devices: -1                                                             
â”‚       precision: 32                                                           
â”‚       check_val_every_n_epoch: 1                                              
â”‚       deterministic: false                                                    
â”‚       strategy: ddp                                                           
â”‚       num_nodes: 1                                                            
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectroscop
â”‚       data_dir: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectroscop
â”‚       log_dir: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectroscopi
â”‚       output_dir: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectrosc
â”‚       work_dir: /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectroscop
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train                                                                   
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['MD17-pcqm4mv2-PT']                                                    
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ test
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ None                                                                    
â””â”€â”€ seed
    â””â”€â”€ 1                                                                       
Seed set to 1
[[36m2025-09-26 10:38:20,432[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.datamodule.DataModule>[0m
train 3378406, val 100, test 100
[[36m2025-09-26 10:38:27,248[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.module.LNNP>[0m
use md17 dataset, model setting is changing.
[[36m2025-09-26 10:38:27,431[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-09-26 10:38:27,431[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-09-26 10:38:27,438[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-09-26 10:38:27,440[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-09-26 10:38:27,441[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-09-26 10:38:27,442[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-09-26 10:38:27,442[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.csv_logs.CSVLogger>[0m
[[36m2025-09-26 10:38:27,445[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-09-26 10:38:27,452[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>[0m
[[36m2025-09-26 10:38:27,458[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-09-26 10:38:27,470[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.[0m
[[36m2025-09-26 10:38:27,487[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - GPU available: True (cuda), used: True[0m
[[36m2025-09-26 10:38:27,488[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - TPU available: False, using: 0 TPU cores[0m
[[36m2025-09-26 10:38:27,488[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - HPU available: False, using: 0 HPUs[0m
[[36m2025-09-26 10:38:27,488[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: pengjuren99 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: creating run
wandb: Tracking run with wandb version 0.21.2
wandb: Run data is saved locally in /home/RenPengju/codes/multiModal_Fusion/Multimodal_Spectroscopic/Pre-training-via-Denoising-hydra-lightning/logs/train/runs/2025-09-26_10-38-20/wandb/run-20250926_103830-5keb8mu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-wind-1
wandb: â­ï¸ View project at https://wandb.ai/pengjuren99/MD17-pcqm4mv2-PT
wandb: ğŸš€ View run at https://wandb.ai/pengjuren99/MD17-pcqm4mv2-PT/runs/5keb8mu7
[[36m2025-09-26 10:38:32,703[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
[[36m2025-09-26 10:38:32,735[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision[0m
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
[[36m2025-09-26 10:38:41,717[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------
[0m
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
train 3378406, val 100, test 100
â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”“
â”ƒ   â”ƒ Name                                                          â”ƒ â€¦ â”ƒ â€¦ â”ƒ  â”ƒ
â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”©
â”‚ 0 â”‚ model                                                         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ M â”‚  â”‚
â”‚ 1 â”‚ model.representation_model                                    â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ M â”‚  â”‚
â”‚ 2 â”‚ model.representation_model.embedding                          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ 3 â”‚ model.representation_model.distance                           â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ 4 â”‚ model.representation_model.distance_expansion                 â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ 5 â”‚ model.representation_model.distance_expansion.cutoff_fn       â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ 6 â”‚ model.representation_model.neighbor_embedding                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ 7 â”‚ model.representation_model.neighbor_embedding.aggr_module     â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ 8 â”‚ model.representation_model.neighbor_embedding.embedding       â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ 9 â”‚ model.representation_model.neighbor_embedding.distance_proj   â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.neighbor_embedding.combine         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.neighbor_embedding.cutoff          â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers                   â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ M â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.aggr_module     â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.layernorm       â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.act             â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.attn_activation â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.cutoff          â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.q_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.k_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.v_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.o_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.vec_proj        â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.dk_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.0.dv_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.aggr_module     â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.layernorm       â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.act             â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.attn_activation â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.cutoff          â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.q_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.k_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.v_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.o_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.vec_proj        â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.dk_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.1.dv_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.aggr_module     â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.layernorm       â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.act             â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.attn_activation â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.cutoff          â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.q_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.k_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.v_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.o_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.vec_proj        â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.dk_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.2.dv_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.aggr_module     â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.layernorm       â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.act             â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.attn_activation â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.cutoff          â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.q_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.k_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.v_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.o_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.vec_proj        â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.dk_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.3.dv_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.aggr_module     â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.layernorm       â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.act             â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.attn_activation â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.cutoff          â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.q_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.k_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.v_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.o_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.vec_proj        â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.dk_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.4.dv_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.aggr_module     â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.layernorm       â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.act             â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.attn_activation â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.cutoff          â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.q_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.k_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.v_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.o_proj          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.vec_proj        â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.dk_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.attention_layers.5.dv_proj         â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.out_norm                           â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.representation_model.out_norm_vec                       â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model                                            â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network                             â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.0                           â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.0.vec1_proj                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.0.vec2_proj                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.0.update_net                â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.0.update_net.0              â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.0.update_net.1              â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.0.update_net.2              â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.0.act                       â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.1                           â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.1.vec1_proj                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.1.vec2_proj                 â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.1.update_net                â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.1.update_net.0              â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.1.update_net.1              â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model.output_network.1.update_net.2              â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise                                      â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network                       â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.0                     â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.0.vec1_proj           â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.0.vec2_proj           â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.0.update_net          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.0.update_net.0        â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.0.update_net.1        â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.0.update_net.2        â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.0.act                 â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.1                     â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.1.vec1_proj           â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.1.vec2_proj           â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.1.update_net          â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.1.update_net.0        â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚   â”‚                                                               â”‚   â”‚ K â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.1.update_net.1        â”‚ â€¦ â”‚ 0 â”‚  â”‚
â”‚ â€¦ â”‚ model.output_model_noise.output_network.1.update_net.2        â”‚ â€¦ â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ model.pos_normalizer                                          â”‚ â€¦ â”‚ 0 â”‚  â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”˜
Trainable params: 1.4 M                                                         
Non-trainable params: 0                                                         
Total params: 1.4 M                                                             
Total estimated model params size (MB): 5                                       
Modules in train mode: 128                                                      
Modules in eval mode: 0                                                         
train 3378406, val 100, test 100
use md17 dataset, model setting is changing.
train 3378406, val 100, test 100
