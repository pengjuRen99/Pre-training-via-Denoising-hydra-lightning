_target_: src.models.module.LNNP   # LightningModule

extras:
  lr_warmup_steps: 1000        # How many steps to warm-up over. Defaults to 0 for no warm-up
  ema_alpha_y: 0.05              # The amount of influence of new losses on the exponential moving average of y
  ema_aplha_dy: 1.0             # The amount of influence of new losses on the exponential moving average of dy
  energy_weight: 0.2            # Weighting factor for energies in the loss function
  force_weight: 0.8             # Weighting factor for forces in the loss function
  denoising_weight: 0.         # Weighting factor for denoising in the loss function.

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.001                               
  weight_decay: 0.0

# scheduler:    # choices=['cosine', 'reduce_on_plateau']
#   _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
#   _partial_: true
#   mode: min
#   factor: 0.8          # Minimum learning rate before early stop
#   patience: 30         # Patience for lr-schedule. Patience per eval-interval of validation
#   min_lr: 1e-7        # Minimum learning rate before early stopping

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: true
  T_max: 400000       # Cosine length if lr_schedule is cosine.

net:
  # _target_: src.models.components.simple_dense_net.SimpleDenseNet   # equivariant-transformer
  # architectural args
  model: equivariant-transformer          # choices=["graph-network", "transformer", "equivariant-transformer"]
  embedding_dimension: 128                # Embedding dimension
  num_layers: 6                           # Number of interaction layers in the model
  num_rbf: 32                             # Number of radial basis functions in model
  activation: silu                        # Activation function, choices=list(act_class_mapping.keys())
  rbf_type: expnorm                       # Type of distance expansion, choices=list(rbf_class_mapping.keys())
  trainable_rbf: false                    # If distance expansion functions should be trainable
  neighbor_embedding: true                # If a neighbor embedding should be applied before interactions
  aggr: add                               # Aggregation function, choices=['add', 'mean', 'max']
  # Transformer specific
  distance_influence: both                # Where distance information is included inside the attention, choices=['keys', 'values', 'both', 'none']
  attn_activation: silu                   # Attention activation function, choices=list(act_class_mapping.keys())
  num_heads: 8                            # Number of attention heads
  layernorm_on_vec: null                  # Whether to apply an equivariant layer norm to vec features. Off by default. choices=['whitened']
  # other args
  derivative: true                       # If true, take the derivative of the prediction w.r.t coordinates
  cutoff_lower: 0.0                       # Lower cutoff for interatomic distances  
  cutoff_upper: 5.0                       # Upper cutoff for interatomic distances
  atom_filter: -1                         # Only sum over atoms with Z > atom_filter
  max_z: 100                              # Maximum atomic number that fits in the embedding matrix
  max_num_neighbors: 32                   # Maximum number of neighbors to consider in the network
  # standardize: false                      # If true, multiply prediction by dataset std and add mean
  reduce_op: add                          # Reduce operation to apply to atomic predictions, choices=['add', 'mean'] 
  position_noise_scale: 0.              # Scale of Gaussian noise added to positions. 

  load_model: null                     # Path to model checkpoint to load before training
  pretrained_model: null                      # If true, load a pretrained model from torchmd-net

  prior_model: null       # Which prior model to use      et. Atomref
  # _target_: src.models.components.priors.Atomref

  output_model: Scalar      # The type of output model      Scalar

  output_model_noise: null    # The type of output model for denoising    VectorOutput
    # _target_: null

  reduce_lr_when_bad: false
  use_dataset_md17: true

# compile model for faster training with pytorch 2.0
compile: false
